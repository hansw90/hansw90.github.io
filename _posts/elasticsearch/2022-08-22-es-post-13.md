---
title: "ES 검색엔진 구축 A to Z (1). Elasticsearch 에게 Lucene이란?"
date: 2022-08-22-00:00:00 -0000
categories: ELASTICSEARCH
---

## 0. 목차
1. 루씬이란?
2. 검색에서 뺴 놓을수 없는 자료구조 (역 인덱스 파일)
3. 색인이란? (index writer)
4. 검색이란? (index searcher)
5. 형태소 분석이란? (analyzer)
6. Wrap up!

## 1. 루씬이란?
[](https://lucene.apache.org/)
[](https://github.com/apache/lucene)

- 오픈소스 기반 검색 라이브러리
- 검색 엔진이 갖춰야 하는 기본 기능 (색인, 검색, 형태소 분석) 모듈을 제공한다.

루씬 기반의 대표적인 검색엔진으로는 __Elasticsearch__ 와 __Solr__ 가 존재한다. (Solr 가 먼저 나왔지만 Elasticsearch가 현재는 범용적으로 사용이 되고 있다)

루씬의 기본 개념을 이해한다면 
- 인덱스(index)
- 문서(Document)
- 필드(Field)
- 용어(Term)
등이 있다.

## 2. 검색에서 빼 놓을수 없는 자료 구조 (역색인 파일)

### 역색인 파일 (Inverted Index Structure)
인덱스를 색인어 기반의 검색을 생성 하기 위해 __색인어에 대한 통계를 저장__하는 구조
즉, 용어에 대해서 문서를 나열 하는 구조가 역인덱스 라고 하는 인덱스 계열이다. 


## 3. 색인이란? (index writer)
Index File Formats은 Segment File 이라고도 한다. Segment File은 여러 Index File 유형 중 하나이다.

[Lucene index file format](https://lucene.apache.org/core/3_0_3/fileformats.html#Index%20File%20Formats)

그래서 색인이 뭔데?
IndexWriter 가 Index File들을 생성하는 과정
- 수정이 불가능한 Immutable Type
  - 생성된 파일 안에 있는 내용을 수정/삭제가 안된다는 말이다.
  - 그러므로 루씬에서는 색인을 할때 Segment 파일을 신규로 생성한다.
  - 그래서 indexwriter 가 색인을 완료하면 commit 이라는 action이 발생한다.
  - 이작업을 반복
- 여러개로 생성된 Segments 파일들을 Merge 라는 작업을 통하여 하나의 색인 파일로 만드는 과정이 필요하다.
- 하나의 index는 하나의 IndexWriter 로 구성된다.

![](https://user-images.githubusercontent.com/2585679/185969915-65ab2b2a-c4cb-45cc-9a7d-ea7f8632c7a1.png)

색인과정정리
IndexWriter -> DocumentWriter -> SegmentMerger - > Directory -> IndexWriter -> Analyzer -> Document -> Fields

## 4. 검색이란? (indexSearcher)

IndexWriter로 색인이 끝나면 IndexSearch로 검색이 가능하다.

IndexSearch 클래스 안에서 searchAfter, search 메소드를 통해 검색한다.

IndexSearch 는 IndexReader를 이용해서 검색을 수행한다.
IndexReader 정보는 indexWriter정보를 통해 가장 최신 segmentFile 정보의 indexReader를 불러온다. 
하나의 Index에는 Segment 별로 N개의 LeafReader가 존재한다. 

검색과정정리
Directory -> IndexWriter -> IndexReader -> IndexSearcher -> Query&CollectorManager -> Sort -> Reduce -> Merge

## 5. 형태소 분석이란?
입력 받은 문자열에서 __검색 가능한 정보 구조로 분석 및 분해 하는 과정__

### 형태소분석 구성요소
- Analyzer
  - 하나의 Tokenizer 와 여러개의 TokenFilter로 구성되어 있다.
- CharFilter
  - 형태소 분석을 하는 과정에서 사전에 입력된 단어중 불필요한 단어를 제거하는 필터이다.
- Tokenizer
- TokenFilter 


형태소 분석 과정
1. Input Tezt
2. Character Filter
3. Filtered Text
4. Tokenizer
5. Tokens
6. Token Filter
7. Filtered Tokens
8. Output Tokens

위 과정에서 Token Filter과정은 정의된 순서에 맞춰 적용이 되기 떄문에 적용시 순서가 중요하다. 

추출된 Token, Position, Offset 정보를 포함해서 Term이라 하고, 이를 이용해서 강조와 동의어에 활용이 된다. 